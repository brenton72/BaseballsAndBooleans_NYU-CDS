{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                             GradientBoostingClassifier)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('D:/Courses/DSGA1001/project/clean_master_last.csv', index_col = 0, low_memory=False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = len(data)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = data.drop('Unnamed: 0.1',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split train and test sample\n",
    "rand = list(range(length))\n",
    "split= int(length*0.8)\n",
    "np.random.shuffle(rand)\n",
    "train_index=rand[:split]\n",
    "test_index=rand[split:]\n",
    "data_train=data.iloc[train_index,:]\n",
    "data_test=data.iloc[test_index,:]\n",
    "lab = 'pitch_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, criterion='entropy', oob_score = True, n_jobs = -1,random_state =50, \n",
    "                                max_features = None, min_samples_leaf = 100)\n",
    "rf_clf.fit(data_train.drop(lab,1), data_train[lab])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "width=0.5\n",
    "ax.bar(np.arange(len(data.columns)-1), rf_clf.feature_importances_, width, color='r')\n",
    "ax.set_xticks(np.arange(len(rf_clf.feature_importances_)))\n",
    "ax.set_xticklabels(data_train.drop(lab,1).columns.values,rotation=90)\n",
    "plt.title('Feature Importance from RF')\n",
    "ax.set_ylabel('Normalized Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_clf.score(data_test.drop(lab,1), data_test[lab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = rf_clf.predict(data_test.drop(lab,1))  == data_test[lab]\n",
    "prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#decision tree\n",
    "from sklearn import tree\n",
    "\n",
    "dt_clf = tree.DecisionTreeClassifier(criterion='entropy', random_state =50, \n",
    "                                     max_features = None, min_samples_leaf = 100)\n",
    "dt_clf = dt_clf.fit(data_train.drop(lab,1),data_train[lab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "width=0.3\n",
    "ax.bar(np.arange(len(data.columns)-1), dt_clf.feature_importances_, width, color='r')\n",
    "ax.set_xticks(np.arange(len(dt_clf.feature_importances_)))\n",
    "ax.set_xticklabels(data_train.drop(lab,1).columns.values,rotation=90)\n",
    "plt.title('Feature Importance from DT')\n",
    "ax.set_ylabel('Normalized Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_clf.score(data_test.drop(lab,1), data_test[lab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = dt_clf.predict(data_test.drop(lab,1))  == data_test[lab]\n",
    "prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(dt_clf.predict(data_test.drop(lab,1)), data_test[lab])\n",
    "acc = (cm[0][0]+cm[1][1]+cm[2][2]+cm[3][3]+cm[4][4]+cm[5][5]+cm[6][6]+cm[7][7]+cm[8][8])/float(sum(sum(cm)))\n",
    "print (\"For data_test, the test accuracy is\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "lr = LogisticRegression(C = 1e30, multi_class='multinomial',solver = 'newton-cg', n_jobs = -1,random_state =50)\n",
    "lr.fit(data_train.drop(lab,1), data_train[lab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(data_train[lab], lr.predict(data_train.drop(lab,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "OVR = OneVsRestClassifier(LogisticRegression()).fit(data_train.drop(lab,1), data_train[lab])\n",
    "#OVO = OneVsOneClassifier(LogisticRegression()).fit(data_train.drop(lab,1), data_train[lab])\n",
    "\n",
    "print ('One vs rest accuracy: %.3f' % OVR.score(data_test.drop(lab,1), data_test[lab]))\n",
    "#print ('One vs one accuracy: %.3f' % OVO.score(data_test.drop(lab,1), data_test[lab]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logloss matrics for multiclass\n",
    "#global, pitcher-base\n",
    "#cluster pitchers\n",
    "#feaeture engineering\n",
    "#LR for single pitcher vs. RF. Nonlinearity\n",
    "#proof of chosing final model, by: charts(feature importance), graphs, tables, accuracy, logloss\n",
    "#percesion analysis:degsign a matrix to set a threshold for whether make a prediction.\n",
    "#decision function, process \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
